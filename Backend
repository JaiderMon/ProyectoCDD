from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import pickle
import numpy as np
import re, string
from keras.models import load_model
from keras.preprocessing.sequence import pad_sequences
from keras.initializers import Orthogonal
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import uvicorn


nltk.download('punkt')
nltk.download('punkt_tab')  
nltk.download('stopwords')
nltk.download('wordnet')

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://44.201.198.24:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Carga modelo y recursos
model = load_model("modelo_emociones.keras", custom_objects={'Orthogonal': Orthogonal})
with open("tokenizer.pickle", "rb") as f:
    tokenizer = pickle.load(f)
with open("label_encoder.pickle", "rb") as f:
    encoder = pickle.load(f)

max_len = 100

# Modelo de entrada
class TextInput(BaseModel):
    texto: str

# Preprocesamiento
def preprocess(text):
    text = text.lower()
    text = re.sub(r"http\S+|www\S+|https\S+", "", text)
    text = re.sub(r"@\w+|\#\w+", "", text)
    text = text.translate(str.maketrans('', '', string.punctuation))
    text = re.sub(r'\d+', '', text)
    tokens = word_tokenize(text)
    stop_words = set(stopwords.words('spanish') + stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]
    tokens = [WordNetLemmatizer().lemmatize(word) for word in tokens]
    return ' '.join(tokens)

# Ruta raíz
@app.get("/")
def home():
    return {"message": "Microservicio de emociones con FastAPI funcionando"}

# Ruta de predicción
@app.post("/predict")
def predict(input_data: TextInput):
    if not input_data.texto:
        raise HTTPException(status_code=400, detail="No text provided")

    text = input_data.texto
    preprocessed = preprocess(text)
    sequence = tokenizer.texts_to_sequences([preprocessed])
    padded = pad_sequences(sequence, maxlen=max_len)
    prediction = model.predict(padded, verbose=0)
    emotion = encoder.inverse_transform([np.argmax(prediction)])[0]

    return {"emotion": emotion}
